{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85341f5c",
   "metadata": {
    "id": "85341f5c"
   },
   "source": [
    "## 1\ufe0f\u20e3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43925a0a",
   "metadata": {
    "id": "43925a0a"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ffbe29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79ffbe29",
    "outputId": "0df62fa4-99e7-4b19-ba40-0ddff2393220"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udda5\ufe0f Device: cuda\n",
      "   GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\ud83d\udda5\ufe0f Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478146e4",
   "metadata": {
    "id": "478146e4"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "SEED = 42\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NOISE_RATE = 0.10  # 10% label noise\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711b7c7",
   "metadata": {
    "id": "b711b7c7"
   },
   "source": [
    "## 2\ufe0f\u20e3 Load Clean Data + Inject Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a5b4f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "51a5b4f4",
    "outputId": "ead5b0f8-120d-498a-a636-6fd52a3f1f22"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcc1 Upload sst2_ci_demo_curated.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-987618ce-94c1-4e89-85b1-9ff04bf142b3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-987618ce-94c1-4e89-85b1-9ff04bf142b3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving sst2_ci_demo_curated.csv to sst2_ci_demo_curated.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "print(\"\ud83d\udcc1 Upload sst2_ci_demo_curated.csv:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e1633a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20e1633a",
    "outputId": "69a69883-7d69-4721-f53f-40ec269767ec"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcca Dataset: 500 samples\n",
      "   Labels: {'positive': 261, 'negative': 239}\n",
      "   CI dangerous: 12 (2.4%)\n"
     ]
    }
   ],
   "source": [
    "# Load full dataset with CI scores\n",
    "df_full = pd.read_csv(\"sst2_ci_demo_curated.csv\")\n",
    "\n",
    "# Get unique samples (base variants only)\n",
    "df = df_full[df_full['variant_id'] == 'base'].copy().reset_index(drop=True)\n",
    "\n",
    "# Create ci_dangerous flag from difficulty column\n",
    "df['ci_dangerous'] = (df['difficulty'] == 'dangerous').astype(int)\n",
    "\n",
    "print(f\"\ud83d\udcca Dataset: {len(df)} samples\")\n",
    "print(f\"   Labels: {df['true_label'].value_counts().to_dict()}\")\n",
    "print(f\"   CI dangerous: {df['ci_dangerous'].sum()} ({100*df['ci_dangerous'].mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a71003f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a71003f",
    "outputId": "a6633728-4931-4cc0-9658-2922ccdd3d55"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Train: 400, Test: 100\n"
     ]
    }
   ],
   "source": [
    "# Label mapping\n",
    "label2id = {\"negative\": 0, \"positive\": 1, \"0\": 0, \"1\": 1, 0: 0, 1: 1}\n",
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "df['label'] = df['true_label'].map(lambda x: label2id.get(x, label2id.get(str(x).lower(), 0)))\n",
    "\n",
    "# Split train/test (80/20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['label'])\n",
    "print(f\"\u2705 Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970f72f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "970f72f6",
    "outputId": "eb74809b-d966-424b-8933-1fd0a042774a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udca5 Noise injected:\n",
      "   Flipped: 40 samples (10.0%)\n",
      "   CI dangerous in flipped: 1\n",
      "   CI dangerous total: 9\n"
     ]
    }
   ],
   "source": [
    "# Create noisy version of training data\n",
    "train_noisy = train_df.copy()\n",
    "\n",
    "# Select random 10% to flip labels (binary flip: 0\u21941)\n",
    "n_flip = int(len(train_noisy) * NOISE_RATE)\n",
    "flip_idx = np.random.choice(train_noisy.index, size=n_flip, replace=False)\n",
    "\n",
    "train_noisy.loc[flip_idx, 'label'] = 1 - train_noisy.loc[flip_idx, 'label']\n",
    "\n",
    "train_noisy['noisy_label'] = train_noisy['label']\n",
    "train_noisy['original_label'] = train_df['label']\n",
    "train_noisy['was_flipped'] = train_noisy['label'] != train_df['label']\n",
    "\n",
    "print(f\"\ud83d\udca5 Noise injected:\")\n",
    "print(f\"   Flipped: {train_noisy['was_flipped'].sum()} samples ({100*train_noisy['was_flipped'].mean():.1f}%)\")\n",
    "print(f\"   CI dangerous in flipped: {train_noisy[train_noisy['was_flipped']]['ci_dangerous'].sum()}\")\n",
    "print(f\"   CI dangerous total: {train_noisy['ci_dangerous'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df8333",
   "metadata": {
    "id": "b7df8333"
   },
   "source": [
    "## 3\ufe0f\u20e3 Use CI Dangerous Flags from CLI Analysis\n",
    "\n",
    "The CSV already contains `difficulty` column from Collapse Index CLI analysis.\n",
    "We use `difficulty == \"dangerous\"` directly - no proxies or simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a574b0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a574b0c",
    "outputId": "ef2b5460-0a89-4a26-e659-ce0bf66e1ade"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcca CI Dangerous Flags:\n",
      "   Dangerous samples: 9 (2.2%)\n",
      "   Safe samples: 391 (97.8%)\n",
      "\n",
      "\ud83c\udfaf Overlap with actual flips:\n",
      "   Flipped samples marked dangerous: 1/40\n",
      "   Precision: 11.1%\n"
     ]
    }
   ],
   "source": [
    "# The CSV already has ci_dangerous column from CLI analysis\n",
    "# Let's see the distribution\n",
    "\n",
    "print(f\"\ud83d\udcca CI Dangerous Flags:\")\n",
    "print(f\"   Dangerous samples: {train_noisy['ci_dangerous'].sum()} ({100*train_noisy['ci_dangerous'].mean():.1f}%)\")\n",
    "print(f\"   Safe samples: {(train_noisy['ci_dangerous'] == 0).sum()} ({100*(train_noisy['ci_dangerous'] == 0).mean():.1f}%)\")\n",
    "\n",
    "# Check how many flipped labels are marked dangerous\n",
    "dangerous_mask = train_noisy['ci_dangerous'] == 1\n",
    "print(f\"\\n\ud83c\udfaf Overlap with actual flips:\")\n",
    "print(f\"   Flipped samples marked dangerous: {train_noisy[train_noisy['was_flipped']]['ci_dangerous'].sum()}/{train_noisy['was_flipped'].sum()}\")\n",
    "if dangerous_mask.sum() > 0:\n",
    "    precision = train_noisy[dangerous_mask]['was_flipped'].sum() / dangerous_mask.sum()\n",
    "    print(f\"   Precision: {precision:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f712d7d",
   "metadata": {
    "id": "7f712d7d"
   },
   "source": [
    "## 4\ufe0f\u20e3 Experiment: Noisy Data (Validation)\n",
    "\n",
    "**Hypothesis:** Removing CI-dangerous samples from noisy data SHOULD help (removes actual noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859f3c6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "859f3c6e",
    "outputId": "bdc34fb8-6561-40a1-b7c4-1a2896d35a4a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Experiment splits:\n",
      "   Baseline (noisy): 400 samples\n",
      "   Curated (noisy): 391 samples (removed 9)\n",
      "   Oracle (clean): 400 samples\n",
      "\n",
      "\ud83d\udcca Removed samples analysis:\n",
      "   Total removed: 9\n",
      "   Were flipped: 1 (11.1%)\n",
      "   Precision: 11.1%\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Train on all noisy data\n",
    "train_baseline_noisy = train_noisy.copy()\n",
    "\n",
    "# Curated: Remove CI-dangerous samples (using actual CLI flags)\n",
    "train_curated_noisy = train_noisy[train_noisy['ci_dangerous'] == 0].copy()\n",
    "\n",
    "# Oracle: Train on perfect labels (no noise)\n",
    "train_oracle = train_df.copy()\n",
    "\n",
    "print(f\"\u2705 Experiment splits:\")\n",
    "print(f\"   Baseline (noisy): {len(train_baseline_noisy)} samples\")\n",
    "print(f\"   Curated (noisy): {len(train_curated_noisy)} samples (removed {len(train_baseline_noisy) - len(train_curated_noisy)})\")\n",
    "print(f\"   Oracle (clean): {len(train_oracle)} samples\")\n",
    "print(f\"\\n\ud83d\udcca Removed samples analysis:\")\n",
    "removed_mask = train_noisy['ci_dangerous'] == 1\n",
    "n_removed = removed_mask.sum()\n",
    "if n_removed > 0:\n",
    "    print(f\"   Total removed: {n_removed}\")\n",
    "    print(f\"   Were flipped: {train_noisy[removed_mask]['was_flipped'].sum()} ({100*train_noisy[removed_mask]['was_flipped'].mean():.1f}%)\")\n",
    "    print(f\"   Precision: {100*train_noisy[removed_mask]['was_flipped'].mean():.1f}%\")\n",
    "else:\n",
    "    print(f\"   No dangerous samples to remove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6e2df",
   "metadata": {
    "id": "06d6e2df"
   },
   "source": [
    "## 5\ufe0f\u20e3 Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa2c03b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "a5abf7f9e1aa40a3adaab6fe905d620b",
      "8102dcd0ebc1449a9022ec98722cbaad",
      "77178229b22b44a6a48045f5d6cdaa2f",
      "7d70cc6005274c4fb9814b48062aff46",
      "e0faf2db94dc4444a9d2481dc10fea80",
      "f949c8b1d34a41da847da23fa4523d7d",
      "32d0bde97e784b09b00ef78efbda7288",
      "acb67dc0a5684822b61ed8c656d6df8f",
      "e8eca408255540a0b610f5b015d2d459",
      "bd38daddf9c846d1bf41c8ee055f4602",
      "6176717a45f34e7aa934e843f58a1e55",
      "81bf0673b4834d08a47b3412569fecf0",
      "235cac2d457e410b86bbacfd9f595eba",
      "a7bd013f0ea448ef9ca2cc6bfafaa81b",
      "c973e7e868ce4b1fa22fb985892df784",
      "1174880cc88e43fba962d217190715a4",
      "b27f9b6e321e41559098ae9b28047c91",
      "31aca3f5c94f4e749d286a0fd6f190af",
      "5482c0b1d95b448e9cc4b72ec8c6bb1b",
      "431b110a0a5d4ae6a1225fcd4241cd09",
      "6ffc55a3e28440b8998f5186bc0925cd",
      "f4af435dba2746f4a374501071585cdc",
      "f67c7fa810ac4c049fd6c653facace05",
      "f8e15f6160b64c44a63eea5c9f5fa549",
      "89858fa9d826493fa0c48f1e4aae4719",
      "1f4cb6744d6347ba8ef2dec2762a7fd1",
      "20635cd7d58c4321ac2782524574ce95",
      "dcd9482c075c4c798ca12d2c6af99d51",
      "ea7ee34b9c8a435f82172ae1ee8b5a72",
      "e228a7ca652e45b78ab369c1b52b2866",
      "a97f5513c8f24afd96ea27c1f07afa46",
      "9749df4526344108999b8f99e06c2c23",
      "2c6a46ec21c044cc82ae13fcebdf5630",
      "c8fdd84eb9cb4bcaba28c852791367eb",
      "ecc04cae5d534ba9a504e56845a77cea",
      "5232c1d4a0294fbea75fcd34f88c765e",
      "f907580ac3724ba586283a0b0d1d1358",
      "b750689314d846a5af104489e99fe284",
      "4f353d21d34c414ab14340806b546ff9",
      "d3a429a85bb649b0b13a8db01fb065ae",
      "3a025b22cf2341e6951ffd28b7d83f48",
      "44d98400936446bdaa8da3699caa20f6",
      "d0d8c484bce74c8280cae0e1edf755af",
      "f39a5b22810341e8a1fc23898fb0f028"
     ]
    },
    "id": "2aa2c03b",
    "outputId": "7d7875b0-7833-4776-fc1e-0b2d5b2ba57d"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5abf7f9e1aa40a3adaab6fe905d620b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81bf0673b4834d08a47b3412569fecf0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f67c7fa810ac4c049fd6c653facace05"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8fdd84eb9cb4bcaba28c852791367eb"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=False, max_length=128)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()[:, 1]\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    auc = roc_auc_score(labels, probs) if len(np.unique(labels)) > 1 else 0.0\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"auc\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c719b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "35d0bf585b604fb68aad64d6b18c72eb",
      "1e01aea950454114b23e1cdf9896fed9",
      "6be7bbc39c3d4a749b67c5673ca47b98",
      "7645f237db174c5e82db5eefbb3606f6",
      "63d9f33aef81454aa1f4459597e01b6e",
      "8af1ae30a72a486799f590b1f542a882",
      "26de25707fdb457a980fbf6595898859",
      "207a8b8325714396bae12308158280ad",
      "dd9bf2258f11474aa488455933358a22",
      "d604a1a050a44a69bca03ba8c337d1b6",
      "e19dd72f206a427e97220dfe052ad994",
      "ead1d86ba90645d2956ef05db6cde475",
      "efb4b31b58ad4298ad23e01b9d7b5edd",
      "6705ac0b48b14e8aa86aa444b5833830",
      "0ee34a64363a4c108032860517449c53",
      "75d36d296b5a4c85a47d97b499b82791",
      "fcdc46bbfc014d7e979fc32ee90d4819",
      "2661a56bfdfb455480a8f55429d9b4b3",
      "5a4c4f5e91914db1b3ecc390912ea7bc",
      "81261bd3e6c244829598fd2563583835",
      "4199de79e65449f08ccd21137ce5c7fe",
      "7e3afa517ed64a9087cb98ceba2fc349",
      "f54b18c6664f4aa2aedd2db5689e4347",
      "5ecf30386780462f8f5cbfb3e6882179",
      "66d5c3ed03d94e4c8de07ffdb0751f05",
      "1e0ee1fc43804b0bb90d57bf53d481b9",
      "a28dd75ace1a4d5c8aa599a90e4eea4c",
      "ee857dd4ea0c46e38841df557e2da841",
      "fedac9d008ba43948a7fdf8a5d2b5d5b",
      "1057c84467c34550aa6b6ca787b22126",
      "22707ce610474178a0097da39c4fdf51",
      "d7a2be17939f47fbba108132d1dbe5db",
      "91f3b889803c4dcca9411ddb569c29ec",
      "fe9d5709c88942e4bd4846c9e74fafe5",
      "b23241ed1eea4067b87a3bf2a6245d43",
      "619469fb193649d881877c4f21586522",
      "550b2663fb1248f698144c0249411f3c",
      "b120cd57ca5c466f98a0352f204de2d1",
      "5168efe5b90241d1b9b9d5d3054e6590",
      "8068c258553a45f3b11d98a00fc40041",
      "21bcf845437c454ab9acd04cac330976",
      "e4dd97f634534e76b651cec08f63bf36",
      "04a0c077026c45e5a3e5d649d3864ca4",
      "9ef46fb0aca34baea445462f9b7e74ac"
     ]
    },
    "id": "52c719b7",
    "outputId": "a09e0064-2ac8-4117-f081-bb15feef873a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35d0bf585b604fb68aad64d6b18c72eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/391 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ead1d86ba90645d2956ef05db6cde475"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f54b18c6664f4aa2aedd2db5689e4347"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe9d5709c88942e4bd4846c9e74fafe5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Datasets prepared\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets\n",
    "def prepare_dataset(df):\n",
    "    ds = Dataset.from_pandas(df[['text', 'label']].reset_index(drop=True))\n",
    "    ds = ds.map(tokenize_function, batched=True)\n",
    "    return ds\n",
    "\n",
    "ds_baseline_noisy = prepare_dataset(train_baseline_noisy)\n",
    "ds_curated_noisy = prepare_dataset(train_curated_noisy)\n",
    "ds_oracle = prepare_dataset(train_oracle)\n",
    "ds_test = prepare_dataset(test_df)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"\u2705 Datasets prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbbe1e",
   "metadata": {
    "id": "34fbbe1e"
   },
   "source": [
    "## 6\ufe0f\u20e3 Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dddc6dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "ed0b2cbf281f468fabf9a90ce9a624f3",
      "1cd8e58e770b4712acc77832a3ecc927",
      "812f7423e0f04319b5677facfb28103d",
      "8a24e9c6077e4c7b82c9953d5704b6f3",
      "d15d3134da7f4b25b38ab6fb1efd8272",
      "b4a74f1d1d1f4f6c885f6f2389758349",
      "6faa091765924f59ac0a9ab6271ed7e6",
      "ff3fd091b17b4b94a6b97a57c2a117fc",
      "5245f821e21b4787bcf60a11eec9efd7",
      "e9885e1e98af4ef7a21c41f372ef4840",
      "b1bba60f4a2d4835acb09bcd9dc6e781"
     ]
    },
    "id": "dddc6dbd",
    "outputId": "2a14bd4c-a618-42cc-e916-6cc2118599cc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Baseline (Noisy)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed0b2cbf281f468fabf9a90ce9a624f3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.666300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Baseline (Noisy): Acc=0.6600, F1=0.7344, AUC=0.8237\n"
     ]
    }
   ],
   "source": [
    "# Train Baseline (Noisy)\n",
    "print(\"\ud83d\ude80 Training Baseline (Noisy)...\")\n",
    "\n",
    "model_baseline_noisy = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_baseline = TrainingArguments(\n",
    "    output_dir=\"./baseline_noisy\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_baseline_noisy = Trainer(\n",
    "    model=model_baseline_noisy,\n",
    "    args=training_args_baseline,\n",
    "    train_dataset=ds_baseline_noisy,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_baseline_noisy.train()\n",
    "results_baseline_noisy = trainer_baseline_noisy.evaluate()\n",
    "print(f\"\u2705 Baseline (Noisy): Acc={results_baseline_noisy['eval_accuracy']:.4f}, F1={results_baseline_noisy['eval_f1']:.4f}, AUC={results_baseline_noisy['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d38461",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "08d38461",
    "outputId": "45a4625a-f2ca-4f2e-cb2f-f4d80cbd2b72"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Curated (Noisy)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.661200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Curated (Noisy): Acc=0.8100, F1=0.8348, AUC=0.8918\n"
     ]
    }
   ],
   "source": [
    "# Train Curated (Noisy)\n",
    "print(\"\ud83d\ude80 Training Curated (Noisy)...\")\n",
    "\n",
    "model_curated_noisy = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_curated = TrainingArguments(\n",
    "    output_dir=\"./curated_noisy\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_curated_noisy = Trainer(\n",
    "    model=model_curated_noisy,\n",
    "    args=training_args_curated,\n",
    "    train_dataset=ds_curated_noisy,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_curated_noisy.train()\n",
    "results_curated_noisy = trainer_curated_noisy.evaluate()\n",
    "print(f\"\u2705 Curated (Noisy): Acc={results_curated_noisy['eval_accuracy']:.4f}, F1={results_curated_noisy['eval_f1']:.4f}, AUC={results_curated_noisy['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae458872",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "ae458872",
    "outputId": "c00606ee-1f8d-48d0-ec09-9b78f9ea9894"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Oracle (Perfect Labels)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.626400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Oracle: Acc=0.8000, F1=0.8182, AUC=0.8986\n"
     ]
    }
   ],
   "source": [
    "# Train Oracle (Perfect Labels)\n",
    "print(\"\ud83d\ude80 Training Oracle (Perfect Labels)...\")\n",
    "\n",
    "model_oracle = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_oracle = TrainingArguments(\n",
    "    output_dir=\"./oracle\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_oracle = Trainer(\n",
    "    model=model_oracle,\n",
    "    args=training_args_oracle,\n",
    "    train_dataset=ds_oracle,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_oracle.train()\n",
    "results_oracle = trainer_oracle.evaluate()\n",
    "print(f\"\u2705 Oracle: Acc={results_oracle['eval_accuracy']:.4f}, F1={results_oracle['eval_f1']:.4f}, AUC={results_oracle['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f0708",
   "metadata": {
    "id": "010f0708"
   },
   "source": [
    "## 7\ufe0f\u20e3 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c745f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13c745f5",
    "outputId": "62151170-fa33-44e2-9982-beaff0ff9b38"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "\ud83d\udcca EXPERIMENT RESULTS - SST-2\n",
      "============================================================\n",
      "      Experiment  Accuracy  F1 Score      AUC\n",
      "Baseline (Noisy)      0.66  0.734375 0.823718\n",
      " Curated (Noisy)      0.81  0.834783 0.891827\n",
      "Oracle (Perfect)      0.80  0.818182 0.898638\n"
     ]
    }
   ],
   "source": [
    "# Compile results\n",
    "results_summary = pd.DataFrame({\n",
    "    \"Experiment\": [\n",
    "        \"Baseline (Noisy)\",\n",
    "        \"Curated (Noisy)\",\n",
    "        \"Oracle (Perfect)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        results_baseline_noisy['eval_accuracy'],\n",
    "        results_curated_noisy['eval_accuracy'],\n",
    "        results_oracle['eval_accuracy']\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        results_baseline_noisy['eval_f1'],\n",
    "        results_curated_noisy['eval_f1'],\n",
    "        results_oracle['eval_f1']\n",
    "    ],\n",
    "    \"AUC\": [\n",
    "        results_baseline_noisy['eval_auc'],\n",
    "        results_curated_noisy['eval_auc'],\n",
    "        results_oracle['eval_auc']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udcca EXPERIMENT RESULTS - SST-2\")\n",
    "print(\"=\"*60)\n",
    "print(results_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21347eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f21347eb",
    "outputId": "a229acc2-3601-494e-9800-c950421fc8b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "\ud83c\udfaf GAP ANALYSIS\n",
      "============================================================\n",
      "Baseline (Noisy):  Acc=0.6600, F1=0.7344, AUC=0.8237\n",
      "Curated (Noisy):   Acc=0.8100, F1=0.8348, AUC=0.8918\n",
      "Oracle (Perfect):  Acc=0.8000, F1=0.8182, AUC=0.8986\n",
      "\n",
      "\ud83d\udcc8 Gap to Oracle closed by CI curation:\n",
      "   Accuracy: +107.1%\n",
      "   F1:       +119.8%\n",
      "   AUC:      +90.9%\n",
      "\n",
      "\ud83c\udf89 VERDICT: CI CURATION WORKS! (3/3 improved)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate gap closure\n",
    "baseline_acc = results_baseline_noisy['eval_accuracy']\n",
    "curated_acc = results_curated_noisy['eval_accuracy']\n",
    "oracle_acc = results_oracle['eval_accuracy']\n",
    "\n",
    "baseline_f1 = results_baseline_noisy['eval_f1']\n",
    "curated_f1 = results_curated_noisy['eval_f1']\n",
    "oracle_f1 = results_oracle['eval_f1']\n",
    "\n",
    "baseline_auc = results_baseline_noisy['eval_auc']\n",
    "curated_auc = results_curated_noisy['eval_auc']\n",
    "oracle_auc = results_oracle['eval_auc']\n",
    "\n",
    "# Gap closure calculations\n",
    "gap_acc = oracle_acc - baseline_acc\n",
    "gap_f1 = oracle_f1 - baseline_f1\n",
    "gap_auc = oracle_auc - baseline_auc\n",
    "\n",
    "gap_closed_acc = ((curated_acc - baseline_acc) / gap_acc * 100) if gap_acc != 0 else 0\n",
    "gap_closed_f1 = ((curated_f1 - baseline_f1) / gap_f1 * 100) if gap_f1 != 0 else 0\n",
    "gap_closed_auc = ((curated_auc - baseline_auc) / gap_auc * 100) if gap_auc != 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83c\udfaf GAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline (Noisy):  Acc={baseline_acc:.4f}, F1={baseline_f1:.4f}, AUC={baseline_auc:.4f}\")\n",
    "print(f\"Curated (Noisy):   Acc={curated_acc:.4f}, F1={curated_f1:.4f}, AUC={curated_auc:.4f}\")\n",
    "print(f\"Oracle (Perfect):  Acc={oracle_acc:.4f}, F1={oracle_f1:.4f}, AUC={oracle_auc:.4f}\")\n",
    "print(f\"\\n\ud83d\udcc8 Gap to Oracle closed by CI curation:\")\n",
    "print(f\"   Accuracy: {gap_closed_acc:+.1f}%\")\n",
    "print(f\"   F1:       {gap_closed_f1:+.1f}%\")\n",
    "print(f\"   AUC:      {gap_closed_auc:+.1f}%\")\n",
    "\n",
    "wins = sum([curated_acc > baseline_acc, curated_f1 > baseline_f1, curated_auc > baseline_auc])\n",
    "if wins == 3:\n",
    "    print(f\"\\n\ud83c\udf89 VERDICT: CI CURATION WORKS! ({wins}/3 improved)\")\n",
    "elif wins >= 2:\n",
    "    print(f\"\\n\ud83d\udfe1 VERDICT: Partial improvement ({wins}/3 improved)\")\n",
    "else:\n",
    "    print(f\"\\n\u274c VERDICT: No clear improvement ({wins}/3 improved)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0154f4ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0154f4ba",
    "outputId": "26d923eb-ddc4-4944-aa34-8c6cc5cdcd51"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Results saved to sst2_curation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_summary.to_csv(\"sst2_curation_results.csv\", index=False)\n",
    "print(\"\u2705 Results saved to sst2_curation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2f2b4",
   "metadata": {
    "id": "20e2f2b4"
   },
   "source": [
    "## 8\ufe0f\u20e3 Interpretation\n",
    "\n",
    "**What this experiment tests:**\n",
    "- Removing samples flagged as `difficulty == \"dangerous\"` by Collapse Index CLI\n",
    "- Uses ACTUAL CLI output - no proxies or simulations\n",
    "\n",
    "**Key Insight:**\n",
    "> CI-guided curation uses the `difficulty` column from Collapse Index CLI analysis. Labs receive the pre-flagged CSV and simply exclude dangerous samples during training - no CI system required on their end."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}