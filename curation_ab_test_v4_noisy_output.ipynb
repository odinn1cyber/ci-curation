{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85341f5c",
   "metadata": {
    "id": "85341f5c"
   },
   "source": [
    "## 1\ufe0f\u20e3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43925a0a",
   "metadata": {
    "id": "43925a0a"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ffbe29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79ffbe29",
    "outputId": "444d2fa2-ebf4-4da0-df1c-204aeccfac48"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udda5\ufe0f Device: cuda\n",
      "   GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\ud83d\udda5\ufe0f Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478146e4",
   "metadata": {
    "id": "478146e4"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "SEED = 42\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NOISE_RATE = 0.10  # 10% label noise\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711b7c7",
   "metadata": {
    "id": "b711b7c7"
   },
   "source": [
    "## 2\ufe0f\u20e3 Load Clean Data + Inject Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a5b4f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "51a5b4f4",
    "outputId": "058adeb8-f4f6-4a97-8d92-8e4704117d5c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcc1 Upload sst2_ci_demo_curated.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1bb292cf-fb66-4314-ab56-e7bac0bda806\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1bb292cf-fb66-4314-ab56-e7bac0bda806\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving sst2_ci_demo_curated.csv to sst2_ci_demo_curated.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "print(\"\ud83d\udcc1 Upload sst2_ci_demo_curated.csv:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e1633a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20e1633a",
    "outputId": "4241fe4a-060d-42d3-c701-387284672187"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcca Dataset: 500 samples\n",
      "   Labels: {'positive': 261, 'negative': 239}\n",
      "   CI dangerous: 12 (2.4%)\n"
     ]
    }
   ],
   "source": [
    "# Load full dataset with CI scores\n",
    "df_full = pd.read_csv(\"sst2_ci_demo_curated.csv\")\n",
    "\n",
    "# Get unique samples (base variants only)\n",
    "df = df_full[df_full['variant_id'] == 'base'].copy().reset_index(drop=True)\n",
    "\n",
    "# Create ci_dangerous flag from difficulty column\n",
    "df['ci_dangerous'] = (df['difficulty'] == 'dangerous').astype(int)\n",
    "\n",
    "print(f\"\ud83d\udcca Dataset: {len(df)} samples\")\n",
    "print(f\"   Labels: {df['true_label'].value_counts().to_dict()}\")\n",
    "print(f\"   CI dangerous: {df['ci_dangerous'].sum()} ({100*df['ci_dangerous'].mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a71003f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a71003f",
    "outputId": "06eb3449-e2b8-4eb1-f8b4-11da6c8caf16"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Train: 400, Test: 100\n"
     ]
    }
   ],
   "source": [
    "# Label mapping\n",
    "label2id = {\"negative\": 0, \"positive\": 1, \"0\": 0, \"1\": 1, 0: 0, 1: 1}\n",
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "df['label'] = df['true_label'].map(lambda x: label2id.get(x, label2id.get(str(x).lower(), 0)))\n",
    "\n",
    "# Split train/test (80/20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['label'])\n",
    "print(f\"\u2705 Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970f72f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "970f72f6",
    "outputId": "d53d8927-5091-49e0-b389-56db02f2f06f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udca5 Noise injected:\n",
      "   Flipped: 40 samples (10.0%)\n",
      "   CI dangerous in flipped: 1\n",
      "   CI dangerous total: 9\n"
     ]
    }
   ],
   "source": [
    "# Create noisy version of training data\n",
    "train_noisy = train_df.copy()\n",
    "\n",
    "# Select random 10% to flip labels (binary flip: 0\u21941)\n",
    "n_flip = int(len(train_noisy) * NOISE_RATE)\n",
    "flip_idx = np.random.choice(train_noisy.index, size=n_flip, replace=False)\n",
    "\n",
    "train_noisy.loc[flip_idx, 'label'] = 1 - train_noisy.loc[flip_idx, 'label']\n",
    "\n",
    "train_noisy['noisy_label'] = train_noisy['label']\n",
    "train_noisy['original_label'] = train_df['label']\n",
    "train_noisy['was_flipped'] = train_noisy['label'] != train_df['label']\n",
    "\n",
    "print(f\"\ud83d\udca5 Noise injected:\")\n",
    "print(f\"   Flipped: {train_noisy['was_flipped'].sum()} samples ({100*train_noisy['was_flipped'].mean():.1f}%)\")\n",
    "print(f\"   CI dangerous in flipped: {train_noisy[train_noisy['was_flipped']]['ci_dangerous'].sum()}\")\n",
    "print(f\"   CI dangerous total: {train_noisy['ci_dangerous'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df8333",
   "metadata": {
    "id": "b7df8333"
   },
   "source": [
    "## 3\ufe0f\u20e3 Use CI Dangerous Flags from CLI Analysis\n",
    "\n",
    "The CSV already contains `difficulty` column from Collapse Index CLI analysis.\n",
    "We use `difficulty == \"dangerous\"` directly - no proxies or simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a574b0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a574b0c",
    "outputId": "09e5b81a-6275-4fae-e77d-bf653d014d57"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcca CI Dangerous Flags:\n",
      "   Dangerous samples: 9 (2.2%)\n",
      "   Safe samples: 391 (97.8%)\n",
      "\n",
      "\ud83c\udfaf Overlap with actual flips:\n",
      "   Flipped samples marked dangerous: 1/40\n",
      "   Precision: 11.1%\n"
     ]
    }
   ],
   "source": [
    "# The CSV already has ci_dangerous column from CLI analysis\n",
    "# Let's see the distribution\n",
    "\n",
    "print(f\"\ud83d\udcca CI Dangerous Flags:\")\n",
    "print(f\"   Dangerous samples: {train_noisy['ci_dangerous'].sum()} ({100*train_noisy['ci_dangerous'].mean():.1f}%)\")\n",
    "print(f\"   Safe samples: {(train_noisy['ci_dangerous'] == 0).sum()} ({100*(train_noisy['ci_dangerous'] == 0).mean():.1f}%)\")\n",
    "\n",
    "# Check how many flipped labels are marked dangerous\n",
    "dangerous_mask = train_noisy['ci_dangerous'] == 1\n",
    "print(f\"\\n\ud83c\udfaf Overlap with actual flips:\")\n",
    "print(f\"   Flipped samples marked dangerous: {train_noisy[train_noisy['was_flipped']]['ci_dangerous'].sum()}/{train_noisy['was_flipped'].sum()}\")\n",
    "if dangerous_mask.sum() > 0:\n",
    "    precision = train_noisy[dangerous_mask]['was_flipped'].sum() / dangerous_mask.sum()\n",
    "    print(f\"   Precision: {precision:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f712d7d",
   "metadata": {
    "id": "7f712d7d"
   },
   "source": [
    "## 4\ufe0f\u20e3 Experiment: Noisy Data (Validation)\n",
    "\n",
    "**Hypothesis:** Removing CI-dangerous samples from noisy data SHOULD help (removes actual noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859f3c6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "859f3c6e",
    "outputId": "a0bf24bd-73ce-4db2-bc30-98b2a29b6dea"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Experiment splits:\n",
      "   Baseline (noisy): 400 samples\n",
      "   Curated (noisy): 391 samples (removed 9)\n",
      "   Oracle (clean): 400 samples\n",
      "\n",
      "\ud83d\udcca Removed samples analysis:\n",
      "   Total removed: 9\n",
      "   Were flipped: 1 (11.1%)\n",
      "   Precision: 11.1%\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Train on all noisy data\n",
    "train_baseline_noisy = train_noisy.copy()\n",
    "\n",
    "# Curated: Remove CI-dangerous samples (using actual CLI flags)\n",
    "train_curated_noisy = train_noisy[train_noisy['ci_dangerous'] == 0].copy()\n",
    "\n",
    "# Oracle: Train on perfect labels (no noise)\n",
    "train_oracle = train_df.copy()\n",
    "\n",
    "print(f\"\u2705 Experiment splits:\")\n",
    "print(f\"   Baseline (noisy): {len(train_baseline_noisy)} samples\")\n",
    "print(f\"   Curated (noisy): {len(train_curated_noisy)} samples (removed {len(train_baseline_noisy) - len(train_curated_noisy)})\")\n",
    "print(f\"   Oracle (clean): {len(train_oracle)} samples\")\n",
    "print(f\"\\n\ud83d\udcca Removed samples analysis:\")\n",
    "removed_mask = train_noisy['ci_dangerous'] == 1\n",
    "n_removed = removed_mask.sum()\n",
    "if n_removed > 0:\n",
    "    print(f\"   Total removed: {n_removed}\")\n",
    "    print(f\"   Were flipped: {train_noisy[removed_mask]['was_flipped'].sum()} ({100*train_noisy[removed_mask]['was_flipped'].mean():.1f}%)\")\n",
    "    print(f\"   Precision: {100*train_noisy[removed_mask]['was_flipped'].mean():.1f}%\")\n",
    "else:\n",
    "    print(f\"   No dangerous samples to remove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6e2df",
   "metadata": {
    "id": "06d6e2df"
   },
   "source": [
    "## 5\ufe0f\u20e3 Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa2c03b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "cda012e5f6ae48449e7e4462d29ae775",
      "9d855d6f98144716b5dae5659e3ed57d",
      "e30a7ea324c24d969ecf655bddb4e8d4",
      "43fd74bd6ce04e6cbcddaed5ca626de5",
      "8822adb81c3447b48888d4c9b0c73ebc",
      "b710be56d0e64d01848bbc72acd9d2eb",
      "25911f31ef644c10a0119a7e03f557a5",
      "0a0277f9b93d45b9a23be32bd6485eaa",
      "287aacc98c06418490ca4de424e4f500",
      "beb5561aa87d44dc9db5cea6425246cc",
      "561774c8ed2c419e8b159a96d8ebe034",
      "f725924eb0cd4361b75b8e147f7de957",
      "789c520124034875b64403b23b053ae9",
      "32c9aa70dda5451dad3594fda6978f48",
      "2da2d7f0029346f4ace9aa01e4b6a393",
      "28aa91e010e4414f9cc1ba1f6fd5e72d",
      "53249e529fb746938cf24576766c2774",
      "f2cbac131b3e46019f043f5bc7f34e41",
      "b6c453f502b64011a9ce52db78fc24e6",
      "7a2e743a3a4d4b3994bf40e35490b90b",
      "3f6cfb26ce8c44b089b7ef090d2ad1f2",
      "ba979216524949cc879ec6c930828710",
      "10c41cecb8a84b94809d596ffadcc2bc",
      "3caadbbea37948feb25918eb87de0dbe",
      "b83a2fc1d810447faab403367878b66d",
      "f527a87c99224d9fb3c8b712eca5bad3",
      "00ba502566274f25a03b4a01d26525f8",
      "a045ee5031294d9dbb7a10e0b4a9e613",
      "ce27ddae07f64aa0aa131199983cf006",
      "e50f2177abbe46759bd8569e094f826a",
      "3652de463fdd4009846e3988765459ce",
      "3cdae45e9df74b82a9e53f734c069706",
      "db560b0cb4d847649984692d38adb83c",
      "176cffad50d149ac91b674ccea42b8e6",
      "1f05d55568214c56a9addb007b36e3da",
      "920cb1a2da5c4d6d929f30a644a3667c",
      "fd9d0f9128f04517ab07bd3e76b94596",
      "35226e5e805a454da8a454dbb96871cd",
      "e6207b2a7dfc404a9e3cf35165ce4663",
      "528c919f180a46f381e020b8909d7094",
      "aa516049b30f45d3944df2419db8da30",
      "f2fc4e086150416a9d1a2729953c7af3",
      "87f02f43cee54f298b7bf6dd85e5098b",
      "68c1f0d46cbe4d1ba07d30dfc8a64dd4"
     ]
    },
    "id": "2aa2c03b",
    "outputId": "92fa042e-3f22-418d-f5dc-859fffaf156a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cda012e5f6ae48449e7e4462d29ae775"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f725924eb0cd4361b75b8e147f7de957"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10c41cecb8a84b94809d596ffadcc2bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "176cffad50d149ac91b674ccea42b8e6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=False, max_length=128)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()[:, 1]\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    auc = roc_auc_score(labels, probs) if len(np.unique(labels)) > 1 else 0.0\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"auc\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c719b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "c590cedf59ad44a39956886757c4a907",
      "5ea6500ee2eb4e2f97d63e755ddbabda",
      "4dfbfb5d19bc40b9ad2d617bae02aaa0",
      "a9f3049de3794c4c828efc5f15740e0f",
      "20cb6e03dcfd4794a771fa6cced7e4a1",
      "4e7fd8bc82424647bbf8132ffcac72b9",
      "2c10f58e9599448fb7d75ab3e82e3fc3",
      "f18e8322b2da4a5498c15e9d33282f64",
      "d0a92401e7914d76905c9f43314f1a4c",
      "1119e813cf834e3d8f9236daf7aacf7b",
      "e683000491c6462fac78448423762f16",
      "c97ad12415234b4187c19bb461357662",
      "24d27bf3711844aeaaac0ddb201e58c8",
      "569819dd092c41e899a7ccfd53ca461a",
      "7bd80c1ecc764bb288e7bfdb6c908296",
      "f5af6000edb94788877f100713279700",
      "4eaf7a2ba4824340a47c326b1388f54d",
      "93382d93d5a34c388ddd874216841699",
      "bee939b6c6d24052aee14c5ba62d939c",
      "4b70b3fc1be641f2bce72f00deffa380",
      "42e8e3c810264fb793d8b7f1c0762439",
      "059cf5e89eae48e8a67e8ede864ea6f0",
      "09ffc21eda894312b549ee1303b40237",
      "b270116b379c45ef98eff4af8f8f4eb0",
      "cce0cb9ff9d94383824d1339e070a7df",
      "a304bc6dfd9c4851929968692f43b59f",
      "3ffa5266309b4bdaa23774b0d4803122",
      "38911af5308a4cfe93b4d11c9b577fec",
      "3589355465d64af8b7caa67d25bd27b9",
      "cb24f2e294eb40fc9e85cbce2174f488",
      "2f82d0eae8724d57a39b37d9f9f80313",
      "7923b6b8195e405c8a10a3db1c3bb50b",
      "4d6f85ac3ccf4594a26e5bd720968a01",
      "900df364a0e44a8db7d476986da03df6",
      "2f601877a488498583d8c85f27e57187",
      "13756f8786d94043a1a1b730f1b67fec",
      "6c456e52b520442d95a18ca04cf5909f",
      "114139d17fd7411a8db65b63f060b3a1",
      "34db47193e394e63a0c5d80445bfb7bf",
      "e21e1c16ca1d445d8b6cb7db1b6c36a6",
      "42de6e59134d42bfa6377a63ba5f2a31",
      "6a3f9b6082d24a178f76af4ae85f3b74",
      "15bdf34f728b46309f7461bdc64d5cb0",
      "d7f506f0e4c441eaa02284764be454cd"
     ]
    },
    "id": "52c719b7",
    "outputId": "37ddddbd-993e-4d41-bc33-22f5120fa173"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c590cedf59ad44a39956886757c4a907"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/391 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97ad12415234b4187c19bb461357662"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09ffc21eda894312b549ee1303b40237"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "900df364a0e44a8db7d476986da03df6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Datasets prepared\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets\n",
    "def prepare_dataset(df):\n",
    "    ds = Dataset.from_pandas(df[['text', 'label']].reset_index(drop=True))\n",
    "    ds = ds.map(tokenize_function, batched=True)\n",
    "    return ds\n",
    "\n",
    "ds_baseline_noisy = prepare_dataset(train_baseline_noisy)\n",
    "ds_curated_noisy = prepare_dataset(train_curated_noisy)\n",
    "ds_oracle = prepare_dataset(train_oracle)\n",
    "ds_test = prepare_dataset(test_df)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"\u2705 Datasets prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbbe1e",
   "metadata": {
    "id": "34fbbe1e"
   },
   "source": [
    "## 6\ufe0f\u20e3 Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dddc6dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "9d357c67afb4416199e83099d373ea47",
      "1bdd4b9a171f4ee5b16da9f762ca0a9f",
      "63ccf8a1a61e47578f160c0bae9a87b9",
      "3d917876d83f4340b523a053a70f5d02",
      "32e9af123d974242a49a2c70558b79a6",
      "49f45118fef246a49bec208d58f3f20d",
      "99444b511aa6418c8a4f0cde2d4af75d",
      "50d1251d432e4c70af410b92e9150ca7",
      "952081f38aa54e4fbc01f10f1599abcf",
      "c001b4a5a61e4a808ffc2379a0f9b8b4",
      "3600e1273332430db670fa4a19b27457"
     ]
    },
    "id": "dddc6dbd",
    "outputId": "cce04d01-108b-4e63-91db-cf5504b93396"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Baseline (Noisy)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d357c67afb4416199e83099d373ea47"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.666300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Baseline (Noisy): Acc=0.6600, F1=0.7344, AUC=0.8237\n"
     ]
    }
   ],
   "source": [
    "# Train Baseline (Noisy)\n",
    "print(\"\ud83d\ude80 Training Baseline (Noisy)...\")\n",
    "\n",
    "model_baseline_noisy = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_baseline = TrainingArguments(\n",
    "    output_dir=\"./baseline_noisy\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_baseline_noisy = Trainer(\n",
    "    model=model_baseline_noisy,\n",
    "    args=training_args_baseline,\n",
    "    train_dataset=ds_baseline_noisy,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_baseline_noisy.train()\n",
    "results_baseline_noisy = trainer_baseline_noisy.evaluate()\n",
    "print(f\"\u2705 Baseline (Noisy): Acc={results_baseline_noisy['eval_accuracy']:.4f}, F1={results_baseline_noisy['eval_f1']:.4f}, AUC={results_baseline_noisy['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d38461",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "08d38461",
    "outputId": "54a575e5-fc27-4de3-a0df-674da2ac14c5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Curated (Noisy)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.661200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Curated (Noisy): Acc=0.8100, F1=0.8348, AUC=0.8918\n"
     ]
    }
   ],
   "source": [
    "# Train Curated (Noisy)\n",
    "print(\"\ud83d\ude80 Training Curated (Noisy)...\")\n",
    "\n",
    "model_curated_noisy = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_curated = TrainingArguments(\n",
    "    output_dir=\"./curated_noisy\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_curated_noisy = Trainer(\n",
    "    model=model_curated_noisy,\n",
    "    args=training_args_curated,\n",
    "    train_dataset=ds_curated_noisy,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_curated_noisy.train()\n",
    "results_curated_noisy = trainer_curated_noisy.evaluate()\n",
    "print(f\"\u2705 Curated (Noisy): Acc={results_curated_noisy['eval_accuracy']:.4f}, F1={results_curated_noisy['eval_f1']:.4f}, AUC={results_curated_noisy['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae458872",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "ae458872",
    "outputId": "557c43ae-8213-428b-8a9f-2681836759d0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Training Oracle (Perfect Labels)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.626400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Oracle: Acc=0.8000, F1=0.8182, AUC=0.8986\n"
     ]
    }
   ],
   "source": [
    "# Train Oracle (Perfect Labels)\n",
    "print(\"\ud83d\ude80 Training Oracle (Perfect Labels)...\")\n",
    "\n",
    "model_oracle = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(device)\n",
    "\n",
    "training_args_oracle = TrainingArguments(\n",
    "    output_dir=\"./oracle\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_oracle = Trainer(\n",
    "    model=model_oracle,\n",
    "    args=training_args_oracle,\n",
    "    train_dataset=ds_oracle,\n",
    "    eval_dataset=ds_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_oracle.train()\n",
    "results_oracle = trainer_oracle.evaluate()\n",
    "print(f\"\u2705 Oracle: Acc={results_oracle['eval_accuracy']:.4f}, F1={results_oracle['eval_f1']:.4f}, AUC={results_oracle['eval_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f0708",
   "metadata": {
    "id": "010f0708"
   },
   "source": [
    "## 7\ufe0f\u20e3 Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c745f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13c745f5",
    "outputId": "0fec8ddb-5eb1-4723-f1e8-caa057bc1cce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "\ud83d\udcca EXPERIMENT RESULTS - SST-2\n",
      "============================================================\n",
      "      Experiment  Accuracy  F1 Score      AUC\n",
      "Baseline (Noisy)      0.66  0.734375 0.823718\n",
      " Curated (Noisy)      0.81  0.834783 0.891827\n",
      "Oracle (Perfect)      0.80  0.818182 0.898638\n"
     ]
    }
   ],
   "source": [
    "# Compile results\n",
    "results_summary = pd.DataFrame({\n",
    "    \"Experiment\": [\n",
    "        \"Baseline (Noisy)\",\n",
    "        \"Curated (Noisy)\",\n",
    "        \"Oracle (Perfect)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        results_baseline_noisy['eval_accuracy'],\n",
    "        results_curated_noisy['eval_accuracy'],\n",
    "        results_oracle['eval_accuracy']\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        results_baseline_noisy['eval_f1'],\n",
    "        results_curated_noisy['eval_f1'],\n",
    "        results_oracle['eval_f1']\n",
    "    ],\n",
    "    \"AUC\": [\n",
    "        results_baseline_noisy['eval_auc'],\n",
    "        results_curated_noisy['eval_auc'],\n",
    "        results_oracle['eval_auc']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udcca EXPERIMENT RESULTS - SST-2\")\n",
    "print(\"=\"*60)\n",
    "print(results_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21347eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f21347eb",
    "outputId": "0290c1db-92d2-4462-997d-6d22c6ee0209"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "\ud83c\udfaf GAP ANALYSIS\n",
      "============================================================\n",
      "Baseline (Noisy):  Acc=0.6600, F1=0.7344, AUC=0.8237\n",
      "Curated (Noisy):   Acc=0.8100, F1=0.8348, AUC=0.8918\n",
      "Oracle (Perfect):  Acc=0.8000, F1=0.8182, AUC=0.8986\n",
      "\n",
      "\ud83d\udcc8 Gap to Oracle closed by CI curation:\n",
      "   Accuracy: +107.1%\n",
      "   F1:       +119.8%\n",
      "   AUC:      +90.9%\n",
      "\n",
      "\ud83c\udf89 VERDICT: CI CURATION WORKS! (3/3 improved)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate gap closure\n",
    "baseline_acc = results_baseline_noisy['eval_accuracy']\n",
    "curated_acc = results_curated_noisy['eval_accuracy']\n",
    "oracle_acc = results_oracle['eval_accuracy']\n",
    "\n",
    "baseline_f1 = results_baseline_noisy['eval_f1']\n",
    "curated_f1 = results_curated_noisy['eval_f1']\n",
    "oracle_f1 = results_oracle['eval_f1']\n",
    "\n",
    "baseline_auc = results_baseline_noisy['eval_auc']\n",
    "curated_auc = results_curated_noisy['eval_auc']\n",
    "oracle_auc = results_oracle['eval_auc']\n",
    "\n",
    "# Gap closure calculations\n",
    "gap_acc = oracle_acc - baseline_acc\n",
    "gap_f1 = oracle_f1 - baseline_f1\n",
    "gap_auc = oracle_auc - baseline_auc\n",
    "\n",
    "gap_closed_acc = ((curated_acc - baseline_acc) / gap_acc * 100) if gap_acc != 0 else 0\n",
    "gap_closed_f1 = ((curated_f1 - baseline_f1) / gap_f1 * 100) if gap_f1 != 0 else 0\n",
    "gap_closed_auc = ((curated_auc - baseline_auc) / gap_auc * 100) if gap_auc != 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83c\udfaf GAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline (Noisy):  Acc={baseline_acc:.4f}, F1={baseline_f1:.4f}, AUC={baseline_auc:.4f}\")\n",
    "print(f\"Curated (Noisy):   Acc={curated_acc:.4f}, F1={curated_f1:.4f}, AUC={curated_auc:.4f}\")\n",
    "print(f\"Oracle (Perfect):  Acc={oracle_acc:.4f}, F1={oracle_f1:.4f}, AUC={oracle_auc:.4f}\")\n",
    "print(f\"\\n\ud83d\udcc8 Gap to Oracle closed by CI curation:\")\n",
    "print(f\"   Accuracy: {gap_closed_acc:+.1f}%\")\n",
    "print(f\"   F1:       {gap_closed_f1:+.1f}%\")\n",
    "print(f\"   AUC:      {gap_closed_auc:+.1f}%\")\n",
    "\n",
    "wins = sum([curated_acc > baseline_acc, curated_f1 > baseline_f1, curated_auc > baseline_auc])\n",
    "if wins == 3:\n",
    "    print(f\"\\n\ud83c\udf89 VERDICT: CI CURATION WORKS! ({wins}/3 improved)\")\n",
    "elif wins >= 2:\n",
    "    print(f\"\\n\ud83d\udfe1 VERDICT: Partial improvement ({wins}/3 improved)\")\n",
    "else:\n",
    "    print(f\"\\n\u274c VERDICT: No clear improvement ({wins}/3 improved)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0154f4ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0154f4ba",
    "outputId": "09193a59-9b1d-479c-d09a-4cb743f87b7c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Results saved to sst2_curation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_summary.to_csv(\"sst2_curation_results.csv\", index=False)\n",
    "print(\"\u2705 Results saved to sst2_curation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2f2b4",
   "metadata": {
    "id": "20e2f2b4"
   },
   "source": [
    "## 8\ufe0f\u20e3 Interpretation\n",
    "\n",
    "**What this experiment tests:**\n",
    "- Removing samples flagged as `difficulty == \"dangerous\"` by Collapse Index CLI\n",
    "- Uses ACTUAL CLI output - no proxies or simulations\n",
    "\n",
    "**Key Insight:**\n",
    "> CI-guided curation uses the `difficulty` column from Collapse Index CLI analysis. Labs receive the pre-flagged CSV and simply exclude dangerous samples during training - no CI system required on their end."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}